general_settings:
  store_model_in_db: true
  store_prompts_in_spend_logs: true

litellm_settings:
  proxy_logging: false
  success_logging: true
  drop_params: true

model_list:
  - model_name: gpt-5.1
    litellm_params:
      model: openai/gpt-5.1
      drop_params: true
      additional_drop_params: [ "stop" ]

  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      drop_params: true
      additional_drop_params: [ "stop" ]

  - model_name: gpt-5-mini
    litellm_params:
      model: openai/gpt-5-mini
      drop_params: true
      additional_drop_params: [ "stop" ]

  - model_name: gpt-5.1-codex-max
    litellm_params:
      model: openai/gpt-5.1-codex-max
      drop_params: true
      additional_drop_params: [ "stop" ]

  - model_name: gpt-5.2-codex
    litellm_params:
      model: openai/gpt-5.2-codex
      drop_params: true
      additional_drop_params: [ "stop" ]

  - model_name: gpt-5.2
    litellm_params:
      model: openai/gpt-5.2
      drop_params: true
      additional_drop_params: [ "stop" ]

  - model_name: qwen3-coder:30b
    litellm_params:
      model: openai/qwen3-coder:30b
      api_base: http://host.docker.internal:11434/v1/
    model_info:
      supports_function_calling: true
      supports_parallel_function_calling: true
      supports_reasoning: false
      supports_response_schema: true

  - model_name: qwen3:32b-q4_K_M
    litellm_params:
      model: openai/qwen3:32b-q4_K_M
      api_base: http://host.docker.internal:11434/v1/
      drop_params: true
    model_info:
      supports_function_calling: true
      supports_parallel_function_calling: false
      supports_reasoning: true
      supports_response_schema: true

  - model_name: qwen3-embedding:4b
    litellm_params:
      model: openai/qwen3-embedding:4b
      api_base: http://host.docker.internal:11434/v1/
      drop_params: true
    model_info:
      supports_function_calling: false
      supports_parallel_function_calling: false
      supports_reasoning: false
      supports_response_schema: true

  - model_name: qwen2.5-coder:7b
    litellm_params:
      model: openai/qwen2.5-coder:7b
      api_base: http://host.docker.internal:11434/v1/
      drop_params: true
    model_info:
      supports_function_calling: false
      supports_parallel_function_calling: false
      supports_reasoning: false
      supports_response_schema: true

  - model_name: phi3.5:3.8b-mini-instruct-q4_K_M
    litellm_params:
      model: openai/phi3.5:3.8b-mini-instruct-q4_K_M
      api_base: http://host.docker.internal:11434/v1/
      drop_params: true
    model_info:
      supports_function_calling: false
      supports_parallel_function_calling: false
      supports_reasoning: false
      supports_response_schema: true
